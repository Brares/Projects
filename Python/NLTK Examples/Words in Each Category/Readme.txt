Given the Brown corpus available from NLTK (Natural Language Processing Tool Kit),
it consists of several categories/genres of texts, write a program that computes:

 How many word tokens does each category/genre have?
 How many word types does each category/genre have?
 What is the vocabulary size of the whole corpus?

The program should compute with the following variations:

(a) with stopwords,
(b) without stopwords,
(c) without stopwords and lemmatization, and
(d) without stopwords and stemming.

Needs Python 3.6